{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Behavior Cloning** \n",
    "***\n",
    "In this project we will be workin on creating a deep neural network and train it to drive the car autonomously in the simulator.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Convolution2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "correction = 0.1\n",
    "#correction array for center, left and right images accessed in the loop below\n",
    "cr_ar = np.array([0,correction,-correction])\n",
    "\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load samples\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "print('load samples')\n",
    "samples = []\n",
    "#forward loop - driving counter clockwise\n",
    "with open('./data1/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "#reverse loop - clockwise run\n",
    "with open('./data2/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "#data from bridge        \n",
    "with open('./data3/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-3-3a80db8c4ca0>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-3a80db8c4ca0>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    source_path = line[i] # 0 - center img, 1- left img and 2- right img\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "print('reading images')        \n",
    "images = []\n",
    "measurements = []\n",
    "for line in samples:\n",
    "    for i in range(3):\n",
    "        source_path = line[i] # 0 - center img, 1- left img and 2- right img\n",
    "        #having multiple folders for different data sets # folder path + img + file path\n",
    "        current_path = './'+line[i].split('/')[-3]+'/IMG/'+line[i].split('/')[-1]\n",
    "        image = cv2.imread(current_path)\n",
    "        images.append(image)\n",
    "        measurement = float(line[3])\n",
    "        measurements.append((measurement+cr_ar[i]))\n",
    "        images.append(np.fliplr(image))\n",
    "        measurements.append(-(measurement+cr_ar[i]))\n",
    "    \n",
    "print('reading images')        \n",
    "\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "\n",
    "\n",
    "#Augment the data\n",
    "\n",
    "# Keras NN\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160,320,3)))\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5))\n",
    "\n",
    "#Lenet Model\n",
    "model.add(Convolution2D(6,5,5,activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(16,5,5,activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))\n",
    "#end lenet model\n",
    "model.compile(loss = 'mse',optimizer = 'adam')\n",
    "print('Training') \n",
    "history_object = model.fit(X_train,y_train,validation_split = 0.2,shuffle=True,nb_epoch = epochs,verbose=1)\n",
    "#\"\"\"\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "model.save('model.h5')\n",
    "#\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code with Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(train_samples, validation_samples) = train_test_split(samples,test_size=0.2)\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "\n",
    "    # Loop forever so the generator never terminates\n",
    "\n",
    "    while 1:\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "\n",
    "            batch_samples = samples[offset:offset + batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                for i in range(3):  # i = 0 - center img, 1- left img and 2- right img\n",
    "\n",
    "                    # having multiple folders for different data sets # folder path + img + file path\n",
    "\n",
    "                    current_path = './' + batch_sample[i].split('/'\n",
    "                            )[-3] + '/IMG/' + batch_sample[i].split('/'\n",
    "                            )[-1]\n",
    "                    image = cv2.imread(current_path)\n",
    "                    angle = float(batch_sample[3])\n",
    "                    images.append(image)\n",
    "                    angles.append(angle + cr_ar[i])\n",
    "                    images.append(np.fliplr(image))\n",
    "                    angles.append(-(angle + cr_ar[i]))\n",
    "\n",
    "            # trim image to only see section with road\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255 - 0.5, input_shape=(160, 320, 3),\n",
    "          output_shape=(160, 320, 3)))\n",
    "model.add(Cropping2D(cropping=((50, 20), (0, 0))))\n",
    "\n",
    "model.add(Convolution2D(6, 5, 5, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(16, 5, 5, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=len(train_samples) * 6,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=len(validation_samples),\n",
    "    nb_epoch=epochs,\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "### print the keys contained in the history object\n",
    "\n",
    "print history_object.history.keys()\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "model.save('model_g_1.h5')\n",
    "\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas for Lane Detection Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the one with the solid yellow lane on the left. This one's more tricky!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
